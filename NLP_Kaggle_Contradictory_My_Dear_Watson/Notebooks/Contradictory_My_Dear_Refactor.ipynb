{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition - NLP - \"Contradictory, My Dear Watson\" - Refactor Notebook\n",
    "\n",
    "## Team: jnees\n",
    "\n",
    "#### [GitHub Repo](https://github.com/jnees/data-science-projects/tree/master/NLP_Kaggle_Contradictory_My_Dear_Watson)\n",
    "\n",
    "#### [Competition Overview](https://www.kaggle.com/c/contradictory-my-dear-watson/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jnees/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import scipy as sp\n",
    "from scipy import spatial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy Language Libraries\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/train_translated.csv\")\n",
    "test = pd.read_csv(\"../Data/test_translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12120 entries, 0 to 12119\n",
      "Data columns (total 8 columns):\n",
      "id               12120 non-null object\n",
      "premise          12120 non-null object\n",
      "hypothesis       12120 non-null object\n",
      "lang_abv         12120 non-null object\n",
      "language         12120 non-null object\n",
      "label            12120 non-null int64\n",
      "hypothesis_en    12120 non-null object\n",
      "premise_en       12120 non-null object\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 757.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5195 entries, 0 to 5194\n",
      "Data columns (total 7 columns):\n",
      "id               5195 non-null object\n",
      "premise          5195 non-null object\n",
      "hypothesis       5195 non-null object\n",
      "lang_abv         5195 non-null object\n",
      "language         5195 non-null object\n",
      "hypothesis_en    5195 non-null object\n",
      "premise_en       5195 non-null object\n",
      "dtypes: object(7)\n",
      "memory usage: 284.2+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  \\\n",
      "0  5130fd2cb5   \n",
      "1  5b72532a0b   \n",
      "2  3931fbe82a   \n",
      "3  5622f0c60b   \n",
      "4  86aaa48b45   \n",
      "\n",
      "                                                                                                                                                                                  premise  \\\n",
      "0                                                                                                                    and these comments were considered in formulating the interim rules.   \n",
      "1                                                                                                       These are issues that we wrestle with in practice groups of law firms, she said.    \n",
      "2                                                                                            Des petites choses comme celles-là font une différence énorme dans ce que j'essaye de faire.   \n",
      "3                                                                                            you know they can't really defend themselves like somebody grown uh say my age you know yeah   \n",
      "4  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสดงออกและได้เล่นหลายบทบาทไปพร้อมกัน ๆ อาจช่วยให้เด็กจับความคล้ายคลึงและความแตกต่างระหว่างผู้คนในด้านความปรารถนา ความเชื่อ และความรู้สึกได้   \n",
      "\n",
      "                                                                          hypothesis  \\\n",
      "0  The rules developed in the interim were put together with these comments in mind.   \n",
      "1                         Practice groups are not permitted to work on these issues.   \n",
      "2                                              J'essayais d'accomplir quelque chose.   \n",
      "3                                 They can't defend themselves because of their age.   \n",
      "4                                    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร   \n",
      "\n",
      "  lang_abv language  label  \\\n",
      "0       en  English      0   \n",
      "1       en  English      2   \n",
      "2       fr   French      0   \n",
      "3       en  English      0   \n",
      "4       th     Thai      1   \n",
      "\n",
      "                                                                       hypothesis_en  \\\n",
      "0  The rules developed in the interim were put together with these comments in mind.   \n",
      "1                         Practice groups are not permitted to work on these issues.   \n",
      "2                                              I was trying to accomplish something.   \n",
      "3                                 They can't defend themselves because of their age.   \n",
      "4                                         Children can see how different ethnicities   \n",
      "\n",
      "                                                                                                                                                                                               premise_en  \n",
      "0                                                                                                                                    and these comments were considered in formulating the interim rules.  \n",
      "1                                                                                                                       These are issues that we wrestle with in practice groups of law firms, she said.   \n",
      "2                                                                                                                                    Little things like these make a huge difference in what I try to do.  \n",
      "3                                                                                                            you know they can't really defend themselves like somebody grown uh say my age you know yeah  \n",
      "4  In role playing as well Opportunities to express and play multiple roles simultaneously may help children capture similarities and differences between people in their desires, beliefs, and feelings.  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The training data is comprised of sentences in 15 languages. English is the primary language in the set with about 57% share. The test data has a similar language distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       56.68\n",
       "Chinese        3.39\n",
       "Arabic         3.31\n",
       "French         3.22\n",
       "Swahili        3.18\n",
       "Urdu           3.14\n",
       "Vietnamese     3.13\n",
       "Russian        3.10\n",
       "Hindi          3.09\n",
       "Greek          3.07\n",
       "Thai           3.06\n",
       "Spanish        3.02\n",
       "German         2.90\n",
       "Turkish        2.90\n",
       "Bulgarian      2.82\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train[\"language\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       56.69\n",
       "Spanish        3.37\n",
       "Russian        3.31\n",
       "Swahili        3.31\n",
       "Urdu           3.23\n",
       "Greek          3.23\n",
       "Turkish        3.21\n",
       "Thai           3.16\n",
       "Arabic         3.06\n",
       "French         3.02\n",
       "German         2.93\n",
       "Chinese        2.91\n",
       "Bulgarian      2.89\n",
       "Hindi          2.89\n",
       "Vietnamese     2.79\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test[\"language\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrict Languages - option for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sample = train[train[\"language\"] == \"English\"].copy()\n",
    "# test_sample = test[test[\"language\"] == \"English\"].copy()\n",
    "\n",
    "# print(train_sample.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_features(raw_df,):\n",
    "    ### Adds feature set to dataframe without vectorizing.\n",
    "    \n",
    "    df = raw_df.copy()\n",
    "    \n",
    "    ### ---------------------------- ###\n",
    "    ###       Similarity Index       ###\n",
    "    ### ---------------------------- ###\n",
    "    \n",
    "    # Function for measuring vector similarity - cosine distance between vectors.\n",
    "    cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine(vec1, vec2)\n",
    "    \n",
    "    def calc_similarity(row):\n",
    "        token1 = nlp(row.premise_en)\n",
    "        token2 = nlp(row.hypothesis_en)\n",
    "        return token1.similarity(token2)\n",
    "    \n",
    "    df[\"similarity\"] = df.apply(calc_similarity, 1)\n",
    "    \n",
    "    \n",
    "    ### ---------------------------- ###\n",
    "    ###       L2 Vector Norms        ###\n",
    "    ### ---------------------------- ###\n",
    "    \n",
    "    def calc_l2_premise(row):\n",
    "        return nlp(row.premise_en).vector_norm\n",
    "\n",
    "    def calc_l2_hypothesis(row):\n",
    "        return nlp(row.hypothesis_en).vector_norm\n",
    "\n",
    "    df[\"L2_premise\"] = df.apply(calc_l2_premise, 1)\n",
    "    df[\"L2_hypothesis\"] = df.apply(calc_l2_hypothesis, 1)\n",
    "    \n",
    "    \n",
    "    ### ---------------------------- ###\n",
    "    ###      Sentiment Intensity     ###\n",
    "    ### ---------------------------- ###\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    df[\"sent_score_p\"] = df[\"premise_en\"].apply(lambda p: sid.polarity_scores(p)[\"compound\"])\n",
    "    df[\"sent_score_h\"] = df[\"premise_en\"].apply(lambda p: sid.polarity_scores(p)[\"compound\"])\n",
    "\n",
    "    df[\"sent_score_intensity_diff\"] = np.abs(df[\"sent_score_p\"]) - np.abs(df[\"sent_score_h\"])\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jnees/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "## Add features\n",
    "train_processed = process_features(train)\n",
    "test_processed = process_features(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Split for cross validation\n",
    "\n",
    "# train_split_pct = 0.7\n",
    "# split_index = int(train_processed.shape[0] * train_split_pct)\n",
    "\n",
    "# train_processed_A = train_processed.iloc[:split_index]\n",
    "# train_processed_B = train_processed.iloc[split_index:]\n",
    "\n",
    "# print(train_processed_A.shape, train_processed_B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vect_test_train(train, test, test_labels=True):\n",
    "    ### Uses same vectorizer on test and training set so that they are ready for model with same dimensions.\n",
    "    \n",
    "    ### ------------------------------ ###\n",
    "    ###        Count Vectorizer        ###\n",
    "    ### ------------------------------ ###\n",
    "    \n",
    "    test_df = test.copy()\n",
    "    train_df = train.copy()\n",
    "    \n",
    "    test_df = test_df.reset_index()\n",
    "    train_df = train_df.reset_index()\n",
    "    \n",
    "    vect_h = CountVectorizer()\n",
    "    vect_p = CountVectorizer()\n",
    "\n",
    "    features = [\n",
    "        \"similarity\",\n",
    "        'L2_premise', \n",
    "        'L2_hypothesis', \n",
    "        'sent_score_p',\n",
    "        'sent_score_h',\n",
    "        'sent_score_intensity_diff',\n",
    "        ]\n",
    "\n",
    "    ## Train Vectorize and Concat with features\n",
    "    X_train_premise = vect_p.fit_transform(train_df.premise_en)\n",
    "    X_train_hyp = vect_h.fit_transform(train_df.hypothesis_en)\n",
    "    X_train_features = train_df[features]\n",
    "    \n",
    "    X_train_premise = pd.DataFrame(X_train_premise.todense())\n",
    "    X_train_hyp = pd.DataFrame(X_train_hyp.todense())\n",
    "    X_train = pd.concat([X_train_premise, X_train_hyp, X_train_features], axis=1)\n",
    "    X_train = X_train.reset_index()\n",
    "    \n",
    "    ## Test Vectorize and Concat with features\n",
    "    X_test_premise = vect_p.transform(test_df.premise_en)\n",
    "    X_test_hyp = vect_h.transform(test_df.hypothesis_en)\n",
    "    X_test_features = test_df[features]\n",
    "\n",
    "    \n",
    "    X_test_premise = pd.DataFrame(X_test_premise.todense())\n",
    "    X_test_hyp = pd.DataFrame(X_test_hyp.todense())\n",
    "    X_test = pd.concat([X_test_premise, X_test_hyp, X_test_features], axis=1)\n",
    "    X_test = X_test.reset_index()\n",
    "    \n",
    "    ## Labels and output \n",
    "    y_train = train_df[\"label\"]\n",
    "    \n",
    "    if test_labels:\n",
    "        y_test = test_df[\"label\"]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "    else:\n",
    "        return X_train, y_train, X_test, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = vect_test_train(train=train_processed, test=test_processed, test_labels=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = X_test.columns\n",
    "train_cols = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test\n",
    "\n",
    "Note that feature function outputs a sparse matrix, so it needs to be returned to a dense matrix to avoid dimension mismatch error when using trained instance on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5558580858085809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cf = RandomForestClassifier(n_estimators=500, min_samples_leaf=20, random_state=1)\n",
    "cf.fit(X_train, y_train)\n",
    "predictions = cf.predict(X_train)\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, predictions))\n",
    "\n",
    "test_predictions = cf.predict(X_test)\n",
    "\n",
    "# print(\"Test accuracy: \", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = pd.Series(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame([train['id'], test_predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
