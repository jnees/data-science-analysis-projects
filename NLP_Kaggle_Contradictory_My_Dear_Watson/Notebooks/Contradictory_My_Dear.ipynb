{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition - NLP - \"Contradictory, My Dear Watson\"\n",
    "\n",
    "## Team: jnees\n",
    "### Notebook 1: Data exploration and Cleaning\n",
    "#### [GitHub Repo](https://github.com/jnees/data-science-projects/tree/master/NLP_Kaggle_Contradictory_My_Dear_Watson)\n",
    "\n",
    "#### [Competition Overview](https://www.kaggle.com/c/contradictory-my-dear-watson/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy import spatial\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/train.csv\")\n",
    "test = pd.read_csv(\"../Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12120 entries, 0 to 12119\n",
      "Data columns (total 6 columns):\n",
      "id            12120 non-null object\n",
      "premise       12120 non-null object\n",
      "hypothesis    12120 non-null object\n",
      "lang_abv      12120 non-null object\n",
      "language      12120 non-null object\n",
      "label         12120 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 568.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5195 entries, 0 to 5194\n",
      "Data columns (total 5 columns):\n",
      "id            5195 non-null object\n",
      "premise       5195 non-null object\n",
      "hypothesis    5195 non-null object\n",
      "lang_abv      5195 non-null object\n",
      "language      5195 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 203.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  \\\n",
      "0  5130fd2cb5   \n",
      "1  5b72532a0b   \n",
      "2  3931fbe82a   \n",
      "3  5622f0c60b   \n",
      "4  86aaa48b45   \n",
      "\n",
      "                                                                                                                                                                                  premise  \\\n",
      "0                                                                                                                    and these comments were considered in formulating the interim rules.   \n",
      "1                                                                                                       These are issues that we wrestle with in practice groups of law firms, she said.    \n",
      "2                                                                                            Des petites choses comme celles-là font une différence énorme dans ce que j'essaye de faire.   \n",
      "3                                                                                            you know they can't really defend themselves like somebody grown uh say my age you know yeah   \n",
      "4  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสดงออกและได้เล่นหลายบทบาทไปพร้อมกัน ๆ อาจช่วยให้เด็กจับความคล้ายคลึงและความแตกต่างระหว่างผู้คนในด้านความปรารถนา ความเชื่อ และความรู้สึกได้   \n",
      "\n",
      "                                                                          hypothesis  \\\n",
      "0  The rules developed in the interim were put together with these comments in mind.   \n",
      "1                         Practice groups are not permitted to work on these issues.   \n",
      "2                                              J'essayais d'accomplir quelque chose.   \n",
      "3                                 They can't defend themselves because of their age.   \n",
      "4                                    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร   \n",
      "\n",
      "  lang_abv language  label  \n",
      "0       en  English      0  \n",
      "1       en  English      2  \n",
      "2       fr   French      0  \n",
      "3       en  English      0  \n",
      "4       th     Thai      1  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The training data is comprised of sentences in 15 languages. English is the primary language in the set with about 57% share. The test data has a similar language distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       56.68\n",
       "Chinese        3.39\n",
       "Arabic         3.31\n",
       "French         3.22\n",
       "Swahili        3.18\n",
       "Urdu           3.14\n",
       "Vietnamese     3.13\n",
       "Russian        3.10\n",
       "Hindi          3.09\n",
       "Greek          3.07\n",
       "Thai           3.06\n",
       "Spanish        3.02\n",
       "German         2.90\n",
       "Turkish        2.90\n",
       "Bulgarian      2.82\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train[\"language\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       56.69\n",
       "Spanish        3.37\n",
       "Swahili        3.31\n",
       "Russian        3.31\n",
       "Greek          3.23\n",
       "Urdu           3.23\n",
       "Turkish        3.21\n",
       "Thai           3.16\n",
       "Arabic         3.06\n",
       "French         3.02\n",
       "German         2.93\n",
       "Chinese        2.91\n",
       "Bulgarian      2.89\n",
       "Hindi          2.89\n",
       "Vietnamese     2.79\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test[\"language\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP feature engineering\n",
    "\n",
    "#### 1. Similarity between vectorized premise and hypothesis. (Cosine distance between vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sample = train[train[\"language\"] == \"English\"].head(2000)\n",
    "train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for measuring vector similarity - cosine distance between vectors.\n",
    "cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(row):\n",
    "    token1 = nlp(row.premise)\n",
    "    token2 = nlp(row.hypothesis)\n",
    "    return token1.similarity(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample[\"similarity\"] = train_sample.apply(calc_similarity, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                                                                                                                                                                         ad5a79456e\n",
      "premise       Increased saving by current generations would expand the nation's capital stock, allowing future generations to better afford the nation's retirement costs while also enjoying higher standards of ...\n",
      "hypothesis    Current generations' increased saving would expand the nation's capital stock, allowing future generations to more easily afford the nation's retirement costs while also enjoying higher standards ...\n",
      "lang_abv                                                                                                                                                                                                           en\n",
      "language                                                                                                                                                                                                      English\n",
      "label                                                                                                                                                                                                               0\n",
      "similarity                                                                                                                                                                                                   0.996021\n",
      "Name: 21, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_sample.iloc[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. L2 Vector Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_l2_premise(row):\n",
    "    return nlp(row.premise).vector_norm\n",
    "\n",
    "def calc_l2_hypothesis(row):\n",
    "    return nlp(row.hypothesis).vector_norm\n",
    "\n",
    "train_sample[\"L2_premise\"] = train_sample.apply(calc_l2_premise, 1)\n",
    "train_sample[\"L2_hypothesis\"] = train_sample.apply(calc_l2_hypothesis, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. CountVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 11491)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "import scipy as sp\n",
    "\n",
    "# X_train_counts = vect.fit_transform(train_sample[\"premise\"])\n",
    "# X_train_counts = X_train_counts + train_sample[['similarity', 'L2_premise']]\n",
    "\n",
    "X_train = sp.sparse.hstack((vect.fit_transform(train_sample.premise), train_sample[['similarity', 'L2_premise', 'L2_hypothesis']].values),format='csr')\n",
    "X_train = sp.sparse.hstack((vect.fit_transform(train_sample.hypothesis), X_train),format='csr')\n",
    "X_train.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "y_train = train_sample[\"label\"]\n",
    "nn = MLPClassifier(hidden_layer_sizes=(8,), activation=\"relu\", random_state=1)\n",
    "nn.fit(X_train, y_train)\n",
    "predictions = nn.predict(X_train)\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6345\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "predictions = DecisionTreeClassifier(max_depth=12).fit(X_train, y_train).predict(X_train)\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
