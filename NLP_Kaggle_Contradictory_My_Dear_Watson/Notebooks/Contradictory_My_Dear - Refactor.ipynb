{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition - NLP - \"Contradictory, My Dear Watson\" - Refactor Notebook\n",
    "\n",
    "## Team: jnees\n",
    "\n",
    "#### [GitHub Repo](https://github.com/jnees/data-science-projects/tree/master/NLP_Kaggle_Contradictory_My_Dear_Watson)\n",
    "\n",
    "#### [Competition Overview](https://www.kaggle.com/c/contradictory-my-dear-watson/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jnees/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import scipy as sp\n",
    "from scipy import spatial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "pd.set_option('max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spacy Language Libraries\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/train.csv\")\n",
    "test = pd.read_csv(\"../Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12120 entries, 0 to 12119\n",
      "Data columns (total 6 columns):\n",
      "id            12120 non-null object\n",
      "premise       12120 non-null object\n",
      "hypothesis    12120 non-null object\n",
      "lang_abv      12120 non-null object\n",
      "language      12120 non-null object\n",
      "label         12120 non-null int64\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 568.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5195 entries, 0 to 5194\n",
      "Data columns (total 5 columns):\n",
      "id            5195 non-null object\n",
      "premise       5195 non-null object\n",
      "hypothesis    5195 non-null object\n",
      "lang_abv      5195 non-null object\n",
      "language      5195 non-null object\n",
      "dtypes: object(5)\n",
      "memory usage: 203.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  \\\n",
      "0  5130fd2cb5   \n",
      "1  5b72532a0b   \n",
      "2  3931fbe82a   \n",
      "3  5622f0c60b   \n",
      "4  86aaa48b45   \n",
      "\n",
      "                                                                                                                                                                                  premise  \\\n",
      "0                                                                                                                    and these comments were considered in formulating the interim rules.   \n",
      "1                                                                                                       These are issues that we wrestle with in practice groups of law firms, she said.    \n",
      "2                                                                                            Des petites choses comme celles-là font une différence énorme dans ce que j'essaye de faire.   \n",
      "3                                                                                            you know they can't really defend themselves like somebody grown uh say my age you know yeah   \n",
      "4  ในการเล่นบทบาทสมมุติก็เช่นกัน โอกาสที่จะได้แสดงออกและได้เล่นหลายบทบาทไปพร้อมกัน ๆ อาจช่วยให้เด็กจับความคล้ายคลึงและความแตกต่างระหว่างผู้คนในด้านความปรารถนา ความเชื่อ และความรู้สึกได้   \n",
      "\n",
      "                                                                          hypothesis  \\\n",
      "0  The rules developed in the interim were put together with these comments in mind.   \n",
      "1                         Practice groups are not permitted to work on these issues.   \n",
      "2                                              J'essayais d'accomplir quelque chose.   \n",
      "3                                 They can't defend themselves because of their age.   \n",
      "4                                    เด็กสามารถเห็นได้ว่าชาติพันธุ์แตกต่างกันอย่างไร   \n",
      "\n",
      "  lang_abv language  label  \n",
      "0       en  English      0  \n",
      "1       en  English      2  \n",
      "2       fr   French      0  \n",
      "3       en  English      0  \n",
      "4       th     Thai      1  \n"
     ]
    }
   ],
   "source": [
    "print(train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview\n",
    "\n",
    "The training data is comprised of sentences in 15 languages. English is the primary language in the set with about 57% share. The test data has a similar language distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       56.68\n",
       "Chinese        3.39\n",
       "Arabic         3.31\n",
       "French         3.22\n",
       "Swahili        3.18\n",
       "Urdu           3.14\n",
       "Vietnamese     3.13\n",
       "Russian        3.10\n",
       "Hindi          3.09\n",
       "Greek          3.07\n",
       "Thai           3.06\n",
       "Spanish        3.02\n",
       "Turkish        2.90\n",
       "German         2.90\n",
       "Bulgarian      2.82\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(train[\"language\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       56.69\n",
       "Spanish        3.37\n",
       "Swahili        3.31\n",
       "Russian        3.31\n",
       "Greek          3.23\n",
       "Urdu           3.23\n",
       "Turkish        3.21\n",
       "Thai           3.16\n",
       "Arabic         3.06\n",
       "French         3.02\n",
       "German         2.93\n",
       "Chinese        2.91\n",
       "Hindi          2.89\n",
       "Bulgarian      2.89\n",
       "Vietnamese     2.79\n",
       "Name: language, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(test[\"language\"].value_counts(normalize=True)*100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restrict Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6870, 6) (2945, 5)\n"
     ]
    }
   ],
   "source": [
    "train_sample = train[train[\"language\"] == \"English\"].copy()\n",
    "test_sample = test[test[\"language\"] == \"English\"].copy()\n",
    "\n",
    "print(train_sample.shape, test_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(raw_df, labels=True):\n",
    "    df = raw_df.copy()\n",
    "    \n",
    "    ### ---------------------------- ###\n",
    "    ###       Similarity Index       ###\n",
    "    ### ---------------------------- ###\n",
    "    \n",
    "    # Function for measuring vector similarity - cosine distance between vectors.\n",
    "    cosine_similarity = lambda vec1, vec2: 1 - spatial.distance.cosine(vec1, vec2)\n",
    "    \n",
    "    def calc_similarity(row):\n",
    "        token1 = nlp(row.premise)\n",
    "        token2 = nlp(row.hypothesis)\n",
    "        return token1.similarity(token2)\n",
    "    \n",
    "    df[\"similarity\"] = df.apply(calc_similarity, 1)\n",
    "    \n",
    "    \n",
    "    ### ---------------------------- ###\n",
    "    ###       L2 Vector Norms        ###\n",
    "    ### ---------------------------- ###\n",
    "    \n",
    "    def calc_l2_premise(row):\n",
    "        return nlp(row.premise).vector_norm\n",
    "\n",
    "    def calc_l2_hypothesis(row):\n",
    "        return nlp(row.hypothesis).vector_norm\n",
    "\n",
    "    df[\"L2_premise\"] = df.apply(calc_l2_premise, 1)\n",
    "    df[\"L2_hypothesis\"] = df.apply(calc_l2_hypothesis, 1)\n",
    "    \n",
    "    \n",
    "    ### ---------------------------- ###\n",
    "    ###      Sentiment Intensity     ###\n",
    "    ### ---------------------------- ###\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    df[\"sent_score_p\"] = df[\"premise\"].apply(lambda p: sid.polarity_scores(p)[\"compound\"])\n",
    "    df[\"sent_score_h\"] = df[\"premise\"].apply(lambda p: sid.polarity_scores(p)[\"compound\"])\n",
    "\n",
    "    df[\"sent_score_intensity_diff\"] = np.abs(df[\"sent_score_p\"]) - np.abs(df[\"sent_score_h\"])\n",
    "\n",
    "    ### ------------------------------ ###\n",
    "    ###        Count Vectorizer        ###\n",
    "    ### ------------------------------ ###\n",
    "    \n",
    "    vect = CountVectorizer()\n",
    "\n",
    "    features = [\n",
    "        \"similarity\",\n",
    "        'L2_premise', \n",
    "        'L2_hypothesis', \n",
    "        'sent_score_p',\n",
    "        'sent_score_h',\n",
    "        'sent_score_intensity_diff',\n",
    "    ]\n",
    "\n",
    "    X = sp.sparse.hstack((vect.fit_transform(df.premise), df[features].values),format='csr')\n",
    "    X = sp.sparse.hstack((vect.fit_transform(df.hypothesis), X),format='csr')\n",
    "    \n",
    "    if labels:\n",
    "        y = df[\"label\"]\n",
    "        return X, y\n",
    "    else:\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jnees/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = process_features(train_sample)\n",
    "X_test = process_features(test_sample, labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9962154294032023\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(32,), activation=\"tanh\", max_iter=300, random_state=1)\n",
    "nn.fit(X_train, y_train)\n",
    "predictions = nn.predict(X_train)\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7513828238719068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "predictions = DecisionTreeClassifier(min_samples_leaf=5).fit(X_train, y_train).predict(X_train)\n",
    "print(accuracy_score(y_train, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
